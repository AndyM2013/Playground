{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "np.set_printoptions(suppress=True) # supress scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw data.\n",
    "final_data = pd.read_pickle(\n",
    "    '../Playground-dataset/03-Walmart-Store-Sales-Forecasting-Dataset/final_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of final_data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_dept</th>\n",
       "      <th>date_x</th>\n",
       "      <th>sales_chg_rt_x</th>\n",
       "      <th>sales_chg_rt_2</th>\n",
       "      <th>sales_chg_rt_y</th>\n",
       "      <th>store_label_0</th>\n",
       "      <th>store_label_1</th>\n",
       "      <th>store_label_2</th>\n",
       "      <th>store_label_3</th>\n",
       "      <th>store_label_4</th>\n",
       "      <th>...</th>\n",
       "      <th>date_x_month_8</th>\n",
       "      <th>date_x_month_9</th>\n",
       "      <th>date_x_month_10</th>\n",
       "      <th>date_x_month_11</th>\n",
       "      <th>date_x_month_12</th>\n",
       "      <th>date_x_wom_1</th>\n",
       "      <th>date_x_wom_2</th>\n",
       "      <th>date_x_wom_3</th>\n",
       "      <th>date_x_wom_4</th>\n",
       "      <th>date_x_wom_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>10_1</td>\n",
       "      <td>2011-02-11</td>\n",
       "      <td>0.441881</td>\n",
       "      <td>-0.033033</td>\n",
       "      <td>0.683508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10_1</td>\n",
       "      <td>2011-02-18</td>\n",
       "      <td>0.228364</td>\n",
       "      <td>0.209259</td>\n",
       "      <td>-0.265154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>10_1</td>\n",
       "      <td>2011-02-25</td>\n",
       "      <td>-0.573973</td>\n",
       "      <td>0.441881</td>\n",
       "      <td>-0.324569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>10_1</td>\n",
       "      <td>2011-03-04</td>\n",
       "      <td>0.112619</td>\n",
       "      <td>0.228364</td>\n",
       "      <td>0.088423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>10_1</td>\n",
       "      <td>2011-03-11</td>\n",
       "      <td>-0.013872</td>\n",
       "      <td>-0.573973</td>\n",
       "      <td>-0.005243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_dept     date_x  sales_chg_rt_x  sales_chg_rt_2  sales_chg_rt_y  \\\n",
       "53       10_1 2011-02-11        0.441881       -0.033033        0.683508   \n",
       "54       10_1 2011-02-18        0.228364        0.209259       -0.265154   \n",
       "55       10_1 2011-02-25       -0.573973        0.441881       -0.324569   \n",
       "56       10_1 2011-03-04        0.112619        0.228364        0.088423   \n",
       "57       10_1 2011-03-11       -0.013872       -0.573973       -0.005243   \n",
       "\n",
       "    store_label_0  store_label_1  store_label_2  store_label_3  store_label_4  \\\n",
       "53              0              0              1              0              0   \n",
       "54              0              0              1              0              0   \n",
       "55              0              0              1              0              0   \n",
       "56              0              0              1              0              0   \n",
       "57              0              0              1              0              0   \n",
       "\n",
       "    ...  date_x_month_8  date_x_month_9  date_x_month_10  date_x_month_11  \\\n",
       "53  ...               0               0                0                0   \n",
       "54  ...               0               0                0                0   \n",
       "55  ...               0               0                0                0   \n",
       "56  ...               0               0                0                0   \n",
       "57  ...               0               0                0                0   \n",
       "\n",
       "    date_x_month_12  date_x_wom_1  date_x_wom_2  date_x_wom_3  date_x_wom_4  \\\n",
       "53                0             0             1             0             0   \n",
       "54                0             0             0             1             0   \n",
       "55                0             0             0             0             1   \n",
       "56                0             1             0             0             0   \n",
       "57                0             0             1             0             0   \n",
       "\n",
       "    date_x_wom_5  \n",
       "53             0  \n",
       "54             0  \n",
       "55             0  \n",
       "56             0  \n",
       "57             0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Preview of final_data:')\n",
    "display(final_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The completed discription of columns:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 299790 entries, 53 to 476332\n",
      "Data columns (total 34 columns):\n",
      "store_dept         299790 non-null object\n",
      "date_x             299790 non-null datetime64[ns]\n",
      "sales_chg_rt_x     299790 non-null float64\n",
      "sales_chg_rt_2     299790 non-null float64\n",
      "sales_chg_rt_y     299790 non-null float64\n",
      "store_label_0      299790 non-null uint8\n",
      "store_label_1      299790 non-null uint8\n",
      "store_label_2      299790 non-null uint8\n",
      "store_label_3      299790 non-null uint8\n",
      "store_label_4      299790 non-null uint8\n",
      "dept_label_0       299790 non-null uint8\n",
      "dept_label_1       299790 non-null uint8\n",
      "dept_label_2       299790 non-null uint8\n",
      "dept_label_3       299790 non-null uint8\n",
      "dept_label_5       299790 non-null uint8\n",
      "dept_label_6       299790 non-null uint8\n",
      "dept_label_7       299790 non-null uint8\n",
      "date_x_month_1     299790 non-null uint8\n",
      "date_x_month_2     299790 non-null uint8\n",
      "date_x_month_3     299790 non-null uint8\n",
      "date_x_month_4     299790 non-null uint8\n",
      "date_x_month_5     299790 non-null uint8\n",
      "date_x_month_6     299790 non-null uint8\n",
      "date_x_month_7     299790 non-null uint8\n",
      "date_x_month_8     299790 non-null uint8\n",
      "date_x_month_9     299790 non-null uint8\n",
      "date_x_month_10    299790 non-null uint8\n",
      "date_x_month_11    299790 non-null uint8\n",
      "date_x_month_12    299790 non-null uint8\n",
      "date_x_wom_1       299790 non-null uint8\n",
      "date_x_wom_2       299790 non-null uint8\n",
      "date_x_wom_3       299790 non-null uint8\n",
      "date_x_wom_4       299790 non-null uint8\n",
      "date_x_wom_5       299790 non-null uint8\n",
      "dtypes: datetime64[ns](1), float64(3), object(1), uint8(29)\n",
      "memory usage: 22.0+ MB\n"
     ]
    }
   ],
   "source": [
    "print('The completed discription of columns:')\n",
    "final_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data[final_data['sales_chg_rt_2'] != np.inf]\n",
    "final_data = final_data[final_data['sales_chg_rt_y'] != np.inf]\n",
    "final_data = final_data[final_data['sales_chg_rt_x'] != np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_dept                        9_98\n",
       "date_x             2012-10-26 00:00:00\n",
       "sales_chg_rt_x                   12550\n",
       "sales_chg_rt_2                   12550\n",
       "sales_chg_rt_y                 7652.69\n",
       "store_label_0                        1\n",
       "store_label_1                        1\n",
       "store_label_2                        1\n",
       "store_label_3                        1\n",
       "store_label_4                        1\n",
       "dept_label_0                         1\n",
       "dept_label_1                         1\n",
       "dept_label_2                         1\n",
       "dept_label_3                         1\n",
       "dept_label_5                         1\n",
       "dept_label_6                         1\n",
       "dept_label_7                         1\n",
       "date_x_month_1                       1\n",
       "date_x_month_2                       1\n",
       "date_x_month_3                       1\n",
       "date_x_month_4                       1\n",
       "date_x_month_5                       1\n",
       "date_x_month_6                       1\n",
       "date_x_month_7                       1\n",
       "date_x_month_8                       1\n",
       "date_x_month_9                       1\n",
       "date_x_month_10                      1\n",
       "date_x_month_11                      1\n",
       "date_x_month_12                      1\n",
       "date_x_wom_1                         1\n",
       "date_x_wom_2                         1\n",
       "date_x_wom_3                         1\n",
       "date_x_wom_4                         1\n",
       "date_x_wom_5                         1\n",
       "dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Input Features\n",
    "\n",
    "There exist inf in some features, thus in order to avoid exploding gradient, I will normalize all features first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# standardize numerical feature\n",
    "final_data_2 = final_data.drop(labels=['date_x','store_dept'], axis=1)\n",
    "scaler = MinMaxScaler(feature_range=(0,1)) # force values limited to (0,1)\n",
    "scaler.fit(final_data_2)\n",
    "\n",
    "final_data_std = pd.DataFrame(scaler.transform(final_data_2),\n",
    "                        index=final_data_2.index.values, \n",
    "                        columns=[col + '_std' for col in final_data_2.columns.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat([final_data[['store_dept','date_x']],final_data_std], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training, Validation and Testing Dataset\n",
    "\n",
    "Noted that the splitting point for training data matches the same splitting timing for training dataset when clustering time series. That is on date `2011-12-31`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame()\n",
    "validation_data = pd.DataFrame()\n",
    "test_data = pd.DataFrame()\n",
    "\n",
    "# Create train and test dataset for each store_dept.\n",
    "for k, group in final_data.groupby('store_dept'):\n",
    "    train_g = group[group['date_x'] <= '2011-12-31'] # match the criterion for clustering time series\n",
    "    remain = group[group['date_x'] > '2011-12-31']\n",
    "    remain_half_row = remain.shape[0] // 2\n",
    "    train_data = train_data.append(train_g)\n",
    "    validation_data = validation_data.append(remain.iloc[:remain_half_row,:]) # half of remaining rows are validation\n",
    "    test_data = test_data.append(remain.iloc[remain_half_row:,:]) # half of remaining rows are testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Size of Training Dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(156545, 34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('The Size of Training Dataset:')\n",
    "display(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Size of Validation Dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(69949, 34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('The Size of Validation Dataset:')\n",
    "display(validation_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Size of Testing Dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(73277, 34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('The Size of Testing Dataset:')\n",
    "display(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 156545 entries, 53 to 476289\n",
      "Data columns (total 34 columns):\n",
      "store_dept             156545 non-null object\n",
      "date_x                 156545 non-null datetime64[ns]\n",
      "sales_chg_rt_x_std     156545 non-null float64\n",
      "sales_chg_rt_2_std     156545 non-null float64\n",
      "sales_chg_rt_y_std     156545 non-null float64\n",
      "store_label_0_std      156545 non-null float64\n",
      "store_label_1_std      156545 non-null float64\n",
      "store_label_2_std      156545 non-null float64\n",
      "store_label_3_std      156545 non-null float64\n",
      "store_label_4_std      156545 non-null float64\n",
      "dept_label_0_std       156545 non-null float64\n",
      "dept_label_1_std       156545 non-null float64\n",
      "dept_label_2_std       156545 non-null float64\n",
      "dept_label_3_std       156545 non-null float64\n",
      "dept_label_5_std       156545 non-null float64\n",
      "dept_label_6_std       156545 non-null float64\n",
      "dept_label_7_std       156545 non-null float64\n",
      "date_x_month_1_std     156545 non-null float64\n",
      "date_x_month_2_std     156545 non-null float64\n",
      "date_x_month_3_std     156545 non-null float64\n",
      "date_x_month_4_std     156545 non-null float64\n",
      "date_x_month_5_std     156545 non-null float64\n",
      "date_x_month_6_std     156545 non-null float64\n",
      "date_x_month_7_std     156545 non-null float64\n",
      "date_x_month_8_std     156545 non-null float64\n",
      "date_x_month_9_std     156545 non-null float64\n",
      "date_x_month_10_std    156545 non-null float64\n",
      "date_x_month_11_std    156545 non-null float64\n",
      "date_x_month_12_std    156545 non-null float64\n",
      "date_x_wom_1_std       156545 non-null float64\n",
      "date_x_wom_2_std       156545 non-null float64\n",
      "date_x_wom_3_std       156545 non-null float64\n",
      "date_x_wom_4_std       156545 non-null float64\n",
      "date_x_wom_5_std       156545 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(32), object(1)\n",
      "memory usage: 41.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Target and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data['sales_chg_rt_x_std']\n",
    "train_x = train_data.drop(labels='sales_chg_rt_x_std', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build up MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_init(layer):\n",
    "    '''\n",
    "    Provide fan in (the number of input units) of each hidden layer\n",
    "    as the component of normalizer.\n",
    "    :param\n",
    "        layer: hidden layer\n",
    "    :return\n",
    "        (-lim, lim): tuple of min and max value for uniform distribution\n",
    "    '''\n",
    "\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up MLP model.\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, fc1_units=128, fc2_units=64):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, output_size)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def get_batch(df, target, batch_size=32):\n",
    "    \"\"\"Helper function to get batch of data for training in Pytorch.\n",
    "    \n",
    "    @params\n",
    "        df: scipy csr matrix\n",
    "        target: pandas series\n",
    "    \n",
    "    \"\"\"\n",
    "    n_batch = floor(df.shape[0]/batch_size)\n",
    "    \n",
    "    complete_df = df.iloc[:n_batch*batch_size,:]\n",
    "    y_target = target[:n_batch*batch_size]\n",
    "\n",
    "    for i in range(0, n_batch*batch_size, batch_size):\n",
    "        batch_feature = complete_df.iloc[i:i+batch_size, :]\n",
    "        batch_y_target = y_target[i:i+batch_size]\n",
    "        \n",
    "        yield batch_feature, batch_y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters.\n",
    "input_size = train_x.shape[1] - 2\n",
    "output_size = 1\n",
    "learning_rate = 0.02\n",
    "batch_size = 32\n",
    "\n",
    "epochs = 15\n",
    "step = 0\n",
    "print_every = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLP(input_size, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15... Loss: 0.000120591\n",
      "Epoch: 1/15... Loss: 0.000019274\n",
      "Epoch: 2/15... Loss: 0.000027100\n",
      "Epoch: 2/15... Loss: 0.000112223\n",
      "Epoch: 3/15... Loss: 0.000025700\n",
      "Epoch: 3/15... Loss: 0.000012083\n",
      "Epoch: 4/15... Loss: 0.000027632\n",
      "Epoch: 4/15... Loss: 0.000012228\n",
      "Epoch: 5/15... Loss: 0.000027877\n",
      "Epoch: 5/15... Loss: 0.000012035\n",
      "Epoch: 6/15... Loss: 0.000029514\n",
      "Epoch: 6/15... Loss: 0.000010516\n",
      "Epoch: 7/15... Loss: 0.000030041\n",
      "Epoch: 7/15... Loss: 0.000010977\n",
      "Epoch: 8/15... Loss: 0.000030358\n",
      "Epoch: 8/15... Loss: 0.000010883\n",
      "Epoch: 9/15... Loss: 0.000031964\n",
      "Epoch: 9/15... Loss: 0.000010448\n",
      "Epoch: 10/15... Loss: 0.000032553\n",
      "Epoch: 10/15... Loss: 0.000010036\n",
      "Epoch: 11/15... Loss: 0.000034587\n",
      "Epoch: 11/15... Loss: 0.000008756\n",
      "Epoch: 12/15... Loss: 0.000034747\n",
      "Epoch: 13/15... Loss: 0.000000244\n",
      "Epoch: 13/15... Loss: 0.000035046\n",
      "Epoch: 14/15... Loss: 0.000000487\n",
      "Epoch: 14/15... Loss: 0.000034900\n",
      "Epoch: 15/15... Loss: 0.000003600\n",
      "Epoch: 15/15... Loss: 0.000031865\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    generator = get_batch(df=train_x, target=train_y, batch_size=batch_size)\n",
    "    for feature, y_true in generator:\n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        feature = feature.drop(labels=['store_dept','date_x'], axis=1) # drop non-numeric columns\n",
    "        \n",
    "        feature = torch.tensor(np.array(feature), dtype=torch.float)\n",
    "        y_true = torch.tensor(np.array(y_true), dtype=torch.float)\n",
    "        \n",
    "        output = mlp_model(feature)\n",
    "        loss = criterion(output, y_true)\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(mlp_model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if step % print_every == 0:\n",
    "            print('Epoch: {}/{}...'.format(e+1, epochs),\n",
    "                 'Loss: {:.9f}'.format(running_loss/print_every))\n",
    "            \n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_dept                        9_98\n",
       "date_x             2011-12-30 00:00:00\n",
       "sales_chg_rt_2                     inf\n",
       "sales_chg_rt_y                     inf\n",
       "store_label_0                        1\n",
       "store_label_1                        1\n",
       "store_label_2                        1\n",
       "store_label_3                        1\n",
       "store_label_4                        1\n",
       "dept_label_0                         1\n",
       "dept_label_1                         1\n",
       "dept_label_2                         1\n",
       "dept_label_3                         1\n",
       "dept_label_5                         1\n",
       "dept_label_6                         1\n",
       "dept_label_7                         1\n",
       "date_x_month_1                       0\n",
       "date_x_month_2                       1\n",
       "date_x_month_3                       1\n",
       "date_x_month_4                       1\n",
       "date_x_month_5                       1\n",
       "date_x_month_6                       1\n",
       "date_x_month_7                       1\n",
       "date_x_month_8                       1\n",
       "date_x_month_9                       1\n",
       "date_x_month_10                      1\n",
       "date_x_month_11                      1\n",
       "date_x_month_12                      1\n",
       "date_x_wom_1                         1\n",
       "date_x_wom_2                         1\n",
       "date_x_wom_3                         1\n",
       "date_x_wom_4                         1\n",
       "date_x_wom_5                         1\n",
       "dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
